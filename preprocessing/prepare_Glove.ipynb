{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Glove vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    \n",
    "    model = {}\n",
    "    with open(gloveFile,'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "        \n",
    "        for line in data:\n",
    "            try:\n",
    "                splitLine = ''\n",
    "                splitLine = line.split(' ')\n",
    "                word = str(splitLine[0])\n",
    "                embedding = [float(val) for val in splitLine[1:]]\n",
    "                assert len(embedding) == 100\n",
    "\n",
    "                model[word] = embedding\n",
    "            except Exception as e:\n",
    "                print('error:', word, embedding, len(embedding),  e)\n",
    "                break\n",
    "                \n",
    "        print (\"Done.\",len(model),\" words loaded!\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_coverage(list_voca, glove):\n",
    "\n",
    "    cnt = 0\n",
    "    for token in list_voca:\n",
    "        if token in glove:\n",
    "            ;\n",
    "        else:\n",
    "            cnt = cnt + 1  \n",
    "\n",
    "    print ('# missing token : ' + str(cnt))\n",
    "    print ('coverage : ' + str( 1 - ( cnt/ float(len(list_voca)) ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_embedding(list_voca, glove, pad_token='_PAD_'):\n",
    "\n",
    "    print('be aware: pad token should be placed in the first index of list_voca')\n",
    "    \n",
    "    list_glove_voca = []\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    for token in list_voca:\n",
    "\n",
    "        if token in glove:\n",
    "            list_glove_voca.append( glove[token] )\n",
    "        else:\n",
    "            if token == pad_token:\n",
    "                print ('add PAD as 0s')\n",
    "                assert len(list_glove_voca) == 0\n",
    "                list_glove_voca.append( np.zeros(100) )  \n",
    "            else:\n",
    "                list_glove_voca.append( np.random.uniform(-0.25, 0.25, 100).tolist() )\n",
    "                cnt = cnt + 1\n",
    "\n",
    "    print ('coverage : ' + str( 1 - ( cnt/ float(len(list_voca)) ) ))\n",
    "    return list_glove_voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 load glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 178153  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove = loadGloveModel('../data/raw/bn_glove.39M.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 read dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic size: 1656\n",
      "# missing token : 58\n",
      "coverage : 0.964975845410628\n"
     ]
    }
   ],
   "source": [
    "list_dic = []\n",
    "# with open('../data/news-19_paragraph_swap-random-1m/whole/dic_mincutN.txt', 'r') as f:\n",
    "# with open('../data/headline_swap_news_v2/whole/dic_mincutN.txt', 'r') as f:\n",
    "# with open('../data/headline_swap_news_v2.5/whole/dic_mincutN.txt', 'r') as f:\n",
    "with open('../data/headline/whole/dic_mincutN.txt', 'r', encoding='utf-8') as f:\n",
    "# with open('../data/paragraph_swap_news_v2.5/whole/dic_mincutN.txt', 'r') as f:\n",
    "    list_dic = f.readlines()\n",
    "    list_dic = [x.strip() for x in list_dic]\n",
    "print('dic size:', len(list_dic))\n",
    "cal_coverage(list_dic, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be aware: pad token should be placed in the first index of list_voca\n",
      "add PAD as 0s\n",
      "coverage : 0.9655797101449275\n",
      "glove size: 1656\n",
      "pad: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# list_glove_voca = create_glove_embedding(list_dic, glove, pad_token='_PAD_')\n",
    "list_glove_voca = create_glove_embedding(list_dic, glove, pad_token='')\n",
    "\n",
    "print('glove size:', len(list_glove_voca))\n",
    "print('pad:', list_glove_voca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 store as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1656, 100)\n"
     ]
    }
   ],
   "source": [
    "np_glove = np.asarray(list_glove_voca, dtype=np.float32)\n",
    "print (np.shape(np_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../data/news-19_paragraph_swap-random-1m/whole/W_embedding.npy', np_glove)\n",
    "# np.save('../data/headline_swap_news_v2/whole/W_embedding.npy', np_glove)\n",
    "# np.save('../data/headline_swap_news_v2.5/whole/W_embedding.npy', np_glove)\n",
    "np.save('../data/headline/whole/W_embedding.npy', np_glove)\n",
    "# np.save('../data/paragraph_swap_news_v2.5/whole/W_embedding.npy', np_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
